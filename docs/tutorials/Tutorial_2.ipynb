{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66892f2a-1c92-47d6-a9c1-8cb26940f251",
   "metadata": {},
   "source": [
    "### Tutorial 2 - How to extend DASF Datasets\n",
    "\n",
    "In this tutorial, we will teach you how you can extend DASF datasets to be loaded dynamically to all architetcure.\n",
    "\n",
    "For this specific scenario we will use DASF Array Dataset class to show you how you can create a dataset like this using a simple NPY file.\n",
    "\n",
    "To start, the first step is create and save a simple NPY file to be loaded by the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38bd978-012f-4599-a249-b20577e3700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Serialize a simple array\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.random((20, 20, 20))\n",
    "\n",
    "np.save(\"data.npy\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b5760-bbca-4613-9958-bbaacd96ced6",
   "metadata": {},
   "source": [
    "Once we have the file saved, we can create our own array dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7774cf93-a8ff-46d6-b378-0a5eff657b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dasf.datasets import DatasetArray\n",
    "\n",
    "dataset = DatasetArray(name=\"My Saved NPY\", root=\"data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f92ca2-ecb6-4241-b2be-726146056259",
   "metadata": {},
   "source": [
    "From this moment, our dataset is not loaded yet. To load the data from NPY file, we need to run the function `load`. This object has the same dynamic generator from the previous tutorial. Here we are using a ipykernel with a GPU, then we are expecting the dataset to lad a CuPy Array. Let's see if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b055d3f-0d96-4f1e-bcde-20bd825976bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd783da-95e1-42cf-8ab9-da5035641a05",
   "metadata": {},
   "source": [
    "Once it is loaded, we can slice the dataset and see what is the type of each slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25dbe78-7abf-4ef2-a564-ed72a0bc79e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cupy._core.core.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[:2, :2, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733a245-13f1-45b3-8b69-0d09a496c61d",
   "metadata": {},
   "source": [
    "What should I do if I'm using a GPU but I want to load a Numpy array?\n",
    "\n",
    "All the datasets have a protected load wrapper for each platform. The code discovers which platform you are in and bind the method to its respective protected mathod.\n",
    "\n",
    "In other words, if you are using `load` in a GPU environment as we are doing here, in fact you are executing the protected method called `_load_gpu`.\n",
    "\n",
    "Then to load Numpy arrays, all you need to do is call directly `_load_cpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab10622-978a-4e2e-af2c-6cd9c4f6c626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._load_cpu()\n",
    "\n",
    "type(dataset[:2, :2, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a38825-1bd7-42f0-8d65-b09553e273b4",
   "metadata": {},
   "source": [
    "If you need to handle a Dask array in a multi clustered environment, you can use the protected lazy methods called `_lazy_*`.\n",
    "\n",
    "For datasets, the respective methods for `load` are `_lazy_load_cpu` and `_lazy_load_gpu`. Both returns a Dask Array but with different metadata.\n",
    "\n",
    "Let's see how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ec3104-8087-406c-aa86-71961740fcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array.core.Array"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._lazy_load_cpu()\n",
    "\n",
    "type(dataset[:2, :2, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc2c21-ce64-42a3-a72a-b9f895decdb9",
   "metadata": {},
   "source": [
    "See how the internal array of this Dask dataset looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a556a1-643d-449e-8f5b-b5223972dbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[:2, :2, :2]._meta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
