:py:mod:`dasf.ml.svm`
=====================

.. py:module:: dasf.ml.svm


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   svm/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   dasf.ml.svm.SVC
   dasf.ml.svm.SVR
   dasf.ml.svm.LinearSVC
   dasf.ml.svm.LinearSVR




.. py:class:: SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, nochange_steps=1000, random_state=None)

   Bases: :py:obj:`dasf.transforms.base.Fit`, :py:obj:`dasf.transforms.base.Predict`, :py:obj:`dasf.transforms.base.GetParams`, :py:obj:`dasf.transforms.base.SetParams`

   .. py:method:: _fit_cpu(X, y, sample_weight=None)


   .. py:method:: _fit_gpu(X, y, sample_weight=None)


   .. py:method:: _predict_cpu(X)


   .. py:method:: _predict_gpu(X)


   .. py:method:: _get_params_cpu(deep=True)


   .. py:method:: _set_params_cpu(**params)



.. py:class:: SVR(kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1, nochange_steps=1000)

   Bases: :py:obj:`dasf.transforms.base.Fit`, :py:obj:`dasf.transforms.base.Predict`

   .. py:method:: _fit_cpu(X, y, sample_weight=None)


   .. py:method:: _fit_gpu(X, y, sample_weight=None)


   .. py:method:: _predict_cpu(X)


   .. py:method:: _predict_gpu(X)



.. py:class:: LinearSVC(epsilon=0.0, tol=0.0001, C=1.0, loss='epsilon_insensitive', fit_intercept=True, intercept_scaling=1.0, dual=True, verbose=0, random_state=None, max_iter=1000, handle=None, penalty='l2', penalized_intercept=False, linesearch_max_iter=100, lbfgs_memory=5, grad_tol=0.0001, change_tol=1e-05, multi_class='ovr')

   Bases: :py:obj:`dasf.transforms.base.Fit`, :py:obj:`dasf.transforms.base.Predict`, :py:obj:`dasf.transforms.base.GetParams`, :py:obj:`dasf.transforms.base.SetParams`

   .. py:method:: _fit_cpu(X, y, sample_weight=None)


   .. py:method:: _fit_gpu(X, y, sample_weight=None)


   .. py:method:: _predict_cpu(X)


   .. py:method:: _predict_gpu(X)



.. py:class:: LinearSVR(epsilon=0.0, tol=0.0001, C=1.0, loss='epsilon_insensitive', fit_intercept=True, intercept_scaling=1.0, dual=True, verbose=0, random_state=None, max_iter=1000, handle=None, penalty='l2', penalized_intercept=False, linesearch_max_iter=100, lbfgs_memory=5, grad_tol=0.0001, change_tol=1e-05, multi_class='ovr')

   Bases: :py:obj:`dasf.transforms.base.Fit`, :py:obj:`dasf.transforms.base.Predict`

   .. py:method:: _fit_cpu(X, y, sample_weight=None)


   .. py:method:: _fit_gpu(X, y, sample_weight=None)


   .. py:method:: _predict_cpu(X)


   .. py:method:: _predict_gpu(X)



