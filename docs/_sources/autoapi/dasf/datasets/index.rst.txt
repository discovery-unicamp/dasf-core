dasf.datasets
=============

.. py:module:: dasf.datasets

.. autoapi-nested-parse::

   Init module for Datasets objects. 



Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/dasf/datasets/base/index
   /autoapi/dasf/datasets/datasets/index
   /autoapi/dasf/datasets/download/index


Classes
-------

.. autoapisummary::

   dasf.datasets.Dataset
   dasf.datasets.DatasetArray
   dasf.datasets.DatasetZarr
   dasf.datasets.DatasetHDF5
   dasf.datasets.DatasetXarray
   dasf.datasets.DatasetLabeled
   dasf.datasets.DatasetDataFrame
   dasf.datasets.DatasetParquet
   dasf.datasets.make_blobs
   dasf.datasets.make_classification


Package Contents
----------------

.. py:class:: Dataset(name, download = False, root = None, *args, **kwargs)

   Bases: :py:obj:`dasf.transforms.base.TargeteredTransform`


       Class representing a generic dataset based on a TargeteredTransform
   object.

   Parameters
   ----------
   name : str
       Symbolic name of the dataset.
   download : bool
       If the dataset must be downloaded (the default is False).
   root : str
       Root download directory (the default is None).
   *args : type
       Additional arguments without keys.
   **kwargs : type
       Additional keyworkded arguments.


   Constructor of the object Dataset.



   .. py:attribute:: _name


   .. py:attribute:: _download


   .. py:attribute:: _root


   .. py:attribute:: _metadata


   .. py:attribute:: _data
      :value: None



   .. py:attribute:: _chunks
      :value: None



   .. py:method:: __set_dataset_cache_dir()

      Generate cached directory in $HOME to store dataset(s).




   .. py:method:: download()

      Skeleton of the download method.




   .. py:method:: __len__()

      Return internal data length.




   .. py:method:: __getitem__(idx)

      Generic __getitem__() function based on internal data.

      Parameters
      ----------
      idx : Any
          Key of the fetched data. It can be an integer or a tuple.




.. py:class:: DatasetArray(name, download = False, root = None, chunks='auto')

   Bases: :py:obj:`Dataset`


       Class representing an dataset wich is defined as an array of a defined
   shape.

   Parameters
   ----------
   name : str
       Symbolic name of the dataset.
   download : bool
       If the dataset must be downloaded (the default is False).
   root : str
       Root download directory (the default is None).
   chunks : Any
       Number of blocks of the array (the default is "auto").


   Constructor of the object DatasetArray.


   .. py:attribute:: _chunks


   .. py:attribute:: _root_file


   .. py:method:: __operator_check__(other)

      Check what type of the data we are handling

      Examples:
          DatasetArray with array-like; or
          DatasetArray with DatasetArray

      Parameters
      ----------
      other : Any
          array-like of DatasetArray for the operation.

      Returns
      -------
      data : Any
          A data representing the internal array or the class itself.



   .. py:method:: __repr__()

      Return a class representation based on internal array.



   .. py:method:: __array__(dtype=None)

      Array interface is required to support most of the array functions.

      Parameters
      ----------
      dtype : Any
          Type of the internal array, default=None (not used)

      Returns
      -------
      data : Any
          A data representing the internal array or the class itself.



   .. py:method:: __array_ufunc__(ufunc, method, *inputs, **kwargs)

      Any class, array subclass or not, can define this method or set
      it to None in order to override the behavior of Arrays ufuncs.

      Parameters
      ----------
      ufunc : Callable
          The ufunc object that was called.

      method : Str
          A string indicating which Ufunc method was called (one of
          "__call__", "reduce", "reduceat", "accumulate", "outer", "inner").

      inputs : Any
          A tuple of the input arguments to the ufunc.

      kwargs : Any
          A dictionary containing the optional input arguments of the ufunc.
          If given, any out arguments, both positional and keyword, are
          passed as a tuple in kwargs. See the discussion in Universal
          functions (ufunc) for details.

      Returns
      -------
      array : array-like
          The return either the result of the operation.




   .. py:method:: __check_op_input(in_data)

      Return the proper type of data for operation

        >>> Result = DatasetArray + Numpy; or
        >>> Result = DatasetArray + DatasetArray

      Parameters
      ----------
      in_data : Any
          Input data to be analyzed.

      Returns
      -------
      data : Any
          A data representing the internal array or the class itself.




   .. py:method:: __add__(other)

      Internal function of adding two array datasets.

      Parameters
      ----------
      other : Any
          A data representing an array or a DatasetArray.

      Returns
      -------
      DatasetArray
          A sum with two arrays.




   .. py:method:: __sub__(other)

      Internal function of subtracting two array datasets.

      Parameters
      ----------
      other : Any
          A data representing an array or a DatasetArray.

      Returns
      -------
      DatasetArry
          A subtraction of two arrays.




   .. py:method:: __mul__(other)

      Internal function of multiplication two array datasets.

      Parameters
      ----------
      other : Any
          A data representing an array or a DatasetArray.

      Returns
      -------
      DatasetArry
          A multiplication of two arrays.




   .. py:method:: __div__(other)

      Internal function of division two array datasets.

      Parameters
      ----------
      other : Any
          A data representing an array or a DatasetArray.

      Returns
      -------
      DatasetArry
          A division of two arrays.




   .. py:method:: __copy_attrs_from_data()

      Extends metadata to new transformed object (after operations).




   .. py:method:: __npy_header()

      Read an array header from a filelike object.




   .. py:method:: _lazy_load(xp, **kwargs)

      Lazy load the dataset using an CPU dask container.

      Parameters
      ----------
      xp : type
          Library used to load the file. It must follow numpy library.
      **kwargs : type
          Additional keyworkded arguments to the load.

      Returns
      -------
      Any
          The data (or a Future load object, for `_lazy` operations).




   .. py:method:: _load(xp, **kwargs)

      Load data using CPU container.

      Parameters
      ----------
      xp : Module
          A module that load data (implement `load` function)
      **kwargs : type
          Additional `kwargs` to `xp.load` function.




   .. py:method:: _load_meta()

      Load metadata to inspect.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: _lazy_load_gpu()

      Load data with GPU container + DASK. (It does not load immediattly)




   .. py:method:: _lazy_load_cpu()

      Load data with CPU container + DASK. (It does not load immediattly)




   .. py:method:: _load_gpu()

      Load data with GPU container (e.g. cupy).




   .. py:method:: _load_cpu()

      Load data with CPU container (e.g. numpy).




   .. py:method:: from_array(array)

      Load data from an existing array.

      Parameters
      ----------
      array : array-like
          Input data to be initialized.



   .. py:method:: load()

      Placeholder for load function.




   .. py:property:: shape
      :type: tuple

      Returns the shape of an array.

      Returns
      -------
      tuple
          A tuple with the shape.




   .. py:method:: metadata()

      Return a dictionary with all metadata information from data.

      Returns
      -------
      dict
          A dictionary with metadata information.




.. py:class:: DatasetZarr(name, download = False, root = None, backend = None, chunks=None)

   Bases: :py:obj:`Dataset`


   Class representing an dataset wich is defined as a Zarr array of a
   defined shape.

   Parameters
   ----------
   name : str
       Symbolic name of the dataset.
   download : bool
       If the dataset must be downloaded (the default is False).
   root : str
       Root download directory (the default is None).
   chunks : Any
       Number of blocks of the array (the default is "auto").


   Constructor of the object DatasetZarr. 


   .. py:attribute:: _backend


   .. py:attribute:: _chunks


   .. py:attribute:: _root_file


   .. py:method:: _lazy_load(xp, **kwargs)

      Lazy load the dataset using an CPU dask container.

      Parameters
      ----------
      xp : type
          Library used to load the file. It must follow numpy library.
      **kwargs : type
          Additional keyworkded arguments to the load.

      Returns
      -------
      Any
          The data (or a Future load object, for `_lazy` operations).




   .. py:method:: _load(xp, **kwargs)

      Load data using CPU container.

      Parameters
      ----------
      xp : Module
          A module that load data (implement `load` function)
      **kwargs : type
          Additional `kwargs` to `xp.load` function.




   .. py:method:: _lazy_load_cpu()

      Load data with CPU container + DASK. (It does not load immediattly)

              



   .. py:method:: _lazy_load_gpu()

      Load data with GPU container + DASK. (It does not load immediattly)

              



   .. py:method:: _load_cpu()

      Load data with CPU container (e.g. numpy).

              



   .. py:method:: _load_gpu()

      Load data with GPU container (e.g. cupy).

              



   .. py:method:: load()

      Placeholder for load function.

              



   .. py:method:: _load_meta()

      Load metadata to inspect.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: __read_zarray(key)

      Returns the value of ZArray JSON metadata.

              



   .. py:property:: shape
      :type: tuple

      Returns the shape of an array.

      Returns
      -------
      tuple
          A tuple with the shape.




   .. py:property:: chunksize
      Returns the chunksize of an array.

      Returns
      -------
      tuple
          A tuple with the chunksize.




   .. py:method:: metadata()

      Return a dictionary with all metadata information from data.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: __repr__()

      Return a class representation based on internal array.




   .. py:method:: __check_op_input(in_data)

      Return the proper type of data for operation

        >>> Result = DatasetZarr + Numpy; or
        >>> Result = DatasetZarr + DatasetZarr

      Parameters
      ----------
      in_data : Any
          Input data to be analyzed.

      Returns
      -------
      data : Any
          A data representing the internal array or the class itself.




   .. py:method:: __add__(other)

      Internal function of adding two array datasets.

      Parameters
      ----------
      other : Any
          A data representing an array or a DatasetArray.

      Returns
      -------
      DatasetArry
          A sum with two arrays.




   .. py:method:: __sub__(other)

      Internal function of subtracting two array datasets.

      Parameters
      ----------
      other : Any
          A data representing an array or a DatasetArray.

      Returns
      -------
      DatasetArry
          A subtraction of two arrays.




   .. py:method:: __mul__(other)

      Internal function of multiplication two array datasets.

      Parameters
      ----------
      other : Any
          A data representing an array or a DatasetArray.

      Returns
      -------
      DatasetArry
          A multiplication of two arrays.




   .. py:method:: __div__(other)

      Internal function of division two array datasets.

      Parameters
      ----------
      other : Any
          A data representing an array or a DatasetArray.

      Returns
      -------
      DatasetArry
          A division of two arrays.




   .. py:method:: __copy_attrs_from_data()

      Extends metadata to new transformed object (after operations).




.. py:class:: DatasetHDF5(name, download = False, root = None, chunks='auto', dataset_path = None)

   Bases: :py:obj:`Dataset`


   Class representing an dataset wich is defined as a HDF5 dataset of a
   defined shape.

   Parameters
   ----------
   name : str
       Symbolic name of the dataset.
   download : bool
       If the dataset must be downloaded (the default is False).
   root : str
       Root download directory (the default is None).
   chunks : Any
       Number of blocks of the array (the default is "auto").
   dataset_path : str
       Relative path of the internal HDF5 dataset (the default is None).


   Constructor of the object DatasetHDF5.



   .. py:attribute:: _chunks


   .. py:attribute:: _root_file


   .. py:attribute:: _dataset_path


   .. py:method:: _lazy_load(xp, **kwargs)

      Lazy load the dataset using an CPU dask container.

      Parameters
      ----------
      xp : type
          Library used to load the file. It must follow numpy library.
      **kwargs : type
          Additional keyworkded arguments to the load.

      Returns
      -------
      Any
          The data (or a Future load object, for `_lazy` operations).




   .. py:method:: _load(xp=None, **kwargs)

      Load data using CPU container.

      Parameters
      ----------
      xp : Module
          A module that load data (implement `load` function) (placeholder).
      **kwargs : type
          Additional `kwargs` to `xp.load` function.




   .. py:method:: _lazy_load_cpu()

      Load data with CPU container + DASK. (It does not load immediattly)




   .. py:method:: _lazy_load_gpu()

      Load data with GPU container + DASK. (It does not load immediattly)




   .. py:method:: _load_cpu()

      Load data with CPU container (e.g. numpy).




   .. py:method:: _load_gpu()

      Load data with GPU container (e.g. cupy).




   .. py:method:: load()

      Placeholder for load function.




   .. py:method:: _load_meta()

      Load metadata to inspect.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: metadata()

      Return a dictionary with all metadata information from data.

      Returns
      -------
      dict
          A dictionary with metadata information.




.. py:class:: DatasetXarray(name, download = False, root = None, chunks=None, data_var=None)

   Bases: :py:obj:`Dataset`


   Class representing an dataset wich is defined as a Xarray dataset of a
   defined shape.

   Parameters
   ----------
   name : str
       Symbolic name of the dataset.
   download : bool
       If the dataset must be downloaded (the default is False).
   root : str
       Root download directory (the default is None).
   chunks : Any
       Number of blocks of the array (the default is "auto").
   data_var : Any
       Key (or index) of the internal Xarray dataset (the default is None).


   Constructor of the object DatasetXarray.



   .. py:attribute:: _chunks


   .. py:attribute:: _root_file


   .. py:attribute:: _data_var


   .. py:method:: _lazy_load_cpu()

      Load data with CPU container + DASK. (It does not load immediattly)




   .. py:method:: _lazy_load_gpu()

      Load data with GPU container + DASK. (It does not load immediattly)




   .. py:method:: _load_cpu()

      Load data with CPU container (e.g. numpy).




   .. py:method:: _load_gpu()

      Load data with GPU container (e.g. cupy).




   .. py:method:: load()

      Placeholder for load function.




   .. py:method:: _load_meta()

      Load metadata to inspect.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: metadata()

      Return a dictionary with all metadata information from data.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: __len__()

      Return internal data length.




   .. py:method:: __getitem__(idx)

      A __getitem__() function based on internal Xarray data.

      Parameters
      ----------
      idx : Any
          Key of the fetched data. It can be an integer or a tuple.




.. py:class:: DatasetLabeled(name, download = False, root = None, chunks='auto')

   Bases: :py:obj:`Dataset`


   A class representing a labeled dataset. Each item is a 2-element tuple,
   where the first element is a array of data and the second element is the
   respective label. The items can be accessed from `dataset[x]`.

   Parameters
   ----------
   name : str
       Symbolic name of the dataset.
   download : bool
       If the dataset must be downloaded (the default is False).
   root : str
       Root download directory (the default is None).
   chunks : Any
       Number of blocks of the array (the default is "auto").

   Attributes
   ----------
   __chunks : type
       Description of attribute `__chunks`.


   Constructor of the object DatasetLabeled.



   .. py:attribute:: _chunks


   .. py:method:: download()

      Download the dataset.




   .. py:method:: metadata()

      Return a dictionary with all metadata information from data
      (train and labels).

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: _lazy_load(xp, **kwargs)

      Lazy load the dataset using an CPU dask container.

      Parameters
      ----------
      xp : type
          Library used to load the file. It must follow numpy library.
      **kwargs : type
          Additional keyworkded arguments to the load.

      Returns
      -------
      Tuple
          A Future object that will return a tuple: (data, label).




   .. py:method:: _load(xp, **kwargs)

      Load data using CPU container.

      Parameters
      ----------
      xp : Module
          A module that load data (implement `load` function)
      **kwargs : type
          Additional `kwargs` to `xp.load` function.

      Returns
      -------
      Tuple
          A 2-element tuple: (data, label)




   .. py:method:: _load_meta()

      Load metadata to inspect.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: _lazy_load_gpu()

      Load data with GPU container + DASK. (It does not load immediattly)




   .. py:method:: _lazy_load_cpu()

      Load data with CPU container + DASK. (It does not load immediattly)




   .. py:method:: _load_gpu()

      Load data with GPU container (e.g. cupy).




   .. py:method:: _load_cpu()

      Load data with CPU container (e.g. numpy).




   .. py:method:: load()

      Placeholder for load function.




   .. py:method:: __getitem__(idx)

      A __getitem__() function for data and labeled data together.

      Parameters
      ----------
      idx : Any
          Key of the fetched data. It can be an integer or a tuple.




.. py:class:: DatasetDataFrame(name, download = True, root = None, chunks='auto')

   Bases: :py:obj:`Dataset`


   Class representing an dataset wich is defined as a dataframe.

   Parameters
   ----------
   name : str
       Symbolic name of the dataset.
   download : bool
       If the dataset must be downloaded (the default is False).
   root : str
       Root download directory (the default is None).
   chunks : Any
       Number of blocks of the array (the default is "auto").


   Constructor of the object DatasetDataFrame.



   .. py:attribute:: _chunks


   .. py:attribute:: _root_file


   .. py:method:: _load_meta()

      Load metadata to inspect.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: metadata()

      Return a dictionary with all metadata information from data.

      Returns
      -------
      dict
          A dictionary with metadata information.




   .. py:method:: _lazy_load_gpu()

      Load data with GPU container + DASK. (It does not load immediattly)




   .. py:method:: _lazy_load_cpu()

      Load data with CPU container + DASK. (It does not load immediattly)




   .. py:method:: _load_gpu()

      Load data with GPU container (e.g. CuDF).




   .. py:method:: _load_cpu()

      Load data with CPU container (e.g. pandas).




   .. py:method:: load()

      Placeholder for load function.




   .. py:property:: shape
      :type: tuple

      Returns the shape of an array.

      Returns
      -------
      tuple
          A tuple with the shape.




   .. py:method:: __len__()

      Return internal data length.



   .. py:method:: __getitem__(idx)

      A __getitem__() function based on internal dataframe.

      Parameters
      ----------
      idx : Any
          Key of the fetched data. It can be an integer or a tuple.




.. py:class:: DatasetParquet(name, download = True, root = None, chunks='auto')

   Bases: :py:obj:`DatasetDataFrame`


       Class representing an dataset wich is defined as a Parquet.

   Parameters
   ----------
   name : str
       Symbolic name of the dataset.
   download : bool
       If the dataset must be downloaded (the default is False).
   root : str
       Root download directory (the default is None).
   chunks : Any
       Number of blocks of the array (the default is "auto").


   Constructor of the object DatasetParquet.



   .. py:method:: _lazy_load_gpu()

      Load data with GPU container + DASK. (It does not load immediattly)




   .. py:method:: _lazy_load_cpu()

      Load data with CPU container + DASK. (It does not load immediattly)




   .. py:method:: _load_gpu()

      Load data with GPU container (e.g. CuDF).




   .. py:method:: _load_cpu()

      Load data with CPU container (e.g. pandas).




.. py:class:: make_blobs

   Generate isotropic Gaussian blobs for clustering.

   For an example of usage, see
   :ref:`sphx_glr_auto_examples_datasets_plot_random_dataset.py`.

   Read more in the :ref:`User Guide <sample_generators>`.

   Parameters
   ----------
   n_samples : int or array-like, default=100
       If int, it is the total number of points equally divided among
       clusters.
       If array-like, each element of the sequence indicates
       the number of samples per cluster.

       .. versionchanged:: v0.20
           one can now pass an array-like to the ``n_samples`` parameter

   n_features : int, default=2
       The number of features for each sample.

   centers : int or array-like of shape (n_centers, n_features), default=None
       The number of centers to generate, or the fixed center locations.
       If n_samples is an int and centers is None, 3 centers are generated.
       If n_samples is array-like, centers must be
       either None or an array of length equal to the length of n_samples.

   cluster_std : float or array-like of float, default=1.0
       The standard deviation of the clusters.

   center_box : tuple of float (min, max), default=(-10.0, 10.0)
       The bounding box for each cluster center when centers are
       generated at random.

   shuffle : bool, default=True
       Shuffle the samples.

   random_state : int, RandomState instance or None, default=None
       Determines random number generation for dataset creation. Pass an int
       for reproducible output across multiple function calls.
       See :term:`Glossary <random_state>`.

   return_centers : bool, default=False
       If True, then return the centers of each cluster.

       .. versionadded:: 0.23

   Returns
   -------
   X : ndarray of shape (n_samples, n_features)
       The generated samples.

   y : ndarray of shape (n_samples,)
       The integer labels for cluster membership of each sample.

   centers : ndarray of shape (n_centers, n_features)
       The centers of each cluster. Only returned if
       ``return_centers=True``.

   See Also
   --------
   make_classification : A more intricate variant.

   Examples
   --------
   >>> from sklearn.datasets import make_blobs
   >>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,
   ...                   random_state=0)
   >>> print(X.shape)
   (10, 2)
   >>> y
   array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])
   >>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,
   ...                   random_state=0)
   >>> print(X.shape)
   (10, 2)
   >>> y
   array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])


   .. py:method:: _lazy_make_blobs_cpu(**kwargs)


   .. py:method:: _lazy_make_blobs_gpu(**kwargs)


   .. py:method:: _make_blobs_cpu(**kwargs)


   .. py:method:: _make_blobs_gpu(**kwargs)


   .. py:method:: __call__(**kwargs)


.. py:class:: make_classification

   Generate a random n-class classification problem.

   This initially creates clusters of points normally distributed (std=1)
   about vertices of an ``n_informative``-dimensional hypercube with sides of
   length ``2*class_sep`` and assigns an equal number of clusters to each
   class. It introduces interdependence between these features and adds
   various types of further noise to the data.

   Without shuffling, ``X`` horizontally stacks features in the following
   order: the primary ``n_informative`` features, followed by ``n_redundant``
   linear combinations of the informative features, followed by ``n_repeated``
   duplicates, drawn randomly with replacement from the informative and
   redundant features. The remaining features are filled with random noise.
   Thus, without shuffling, all useful features are contained in the columns
   ``X[:, :n_informative + n_redundant + n_repeated]``.

   For an example of usage, see
   :ref:`sphx_glr_auto_examples_datasets_plot_random_dataset.py`.

   Read more in the :ref:`User Guide <sample_generators>`.

   Parameters
   ----------
   n_samples : int, default=100
       The number of samples.

   n_features : int, default=20
       The total number of features. These comprise ``n_informative``
       informative features, ``n_redundant`` redundant features,
       ``n_repeated`` duplicated features and
       ``n_features-n_informative-n_redundant-n_repeated`` useless features
       drawn at random.

   n_informative : int, default=2
       The number of informative features. Each class is composed of a number
       of gaussian clusters each located around the vertices of a hypercube
       in a subspace of dimension ``n_informative``. For each cluster,
       informative features are drawn independently from  N(0, 1) and then
       randomly linearly combined within each cluster in order to add
       covariance. The clusters are then placed on the vertices of the
       hypercube.

   n_redundant : int, default=2
       The number of redundant features. These features are generated as
       random linear combinations of the informative features.

   n_repeated : int, default=0
       The number of duplicated features, drawn randomly from the informative
       and the redundant features.

   n_classes : int, default=2
       The number of classes (or labels) of the classification problem.

   n_clusters_per_class : int, default=2
       The number of clusters per class.

   weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None
       The proportions of samples assigned to each class. If None, then
       classes are balanced. Note that if ``len(weights) == n_classes - 1``,
       then the last class weight is automatically inferred.
       More than ``n_samples`` samples may be returned if the sum of
       ``weights`` exceeds 1. Note that the actual class proportions will
       not exactly match ``weights`` when ``flip_y`` isn't 0.

   flip_y : float, default=0.01
       The fraction of samples whose class is assigned randomly. Larger
       values introduce noise in the labels and make the classification
       task harder. Note that the default setting flip_y > 0 might lead
       to less than ``n_classes`` in y in some cases.

   class_sep : float, default=1.0
       The factor multiplying the hypercube size.  Larger values spread
       out the clusters/classes and make the classification task easier.

   hypercube : bool, default=True
       If True, the clusters are put on the vertices of a hypercube. If
       False, the clusters are put on the vertices of a random polytope.

   shift : float, ndarray of shape (n_features,) or None, default=0.0
       Shift features by the specified value. If None, then features
       are shifted by a random value drawn in [-class_sep, class_sep].

   scale : float, ndarray of shape (n_features,) or None, default=1.0
       Multiply features by the specified value. If None, then features
       are scaled by a random value drawn in [1, 100]. Note that scaling
       happens after shifting.

   shuffle : bool, default=True
       Shuffle the samples and the features.

   random_state : int, RandomState instance or None, default=None
       Determines random number generation for dataset creation. Pass an int
       for reproducible output across multiple function calls.
       See :term:`Glossary <random_state>`.

   Returns
   -------
   X : ndarray of shape (n_samples, n_features)
       The generated samples.

   y : ndarray of shape (n_samples,)
       The integer labels for class membership of each sample.

   See Also
   --------
   make_blobs : Simplified variant.
   make_multilabel_classification : Unrelated generator for multilabel tasks.

   Notes
   -----
   The algorithm is adapted from Guyon [1] and was designed to generate
   the "Madelon" dataset.

   References
   ----------
   .. [1] I. Guyon, "Design of experiments for the NIPS 2003 variable
          selection benchmark", 2003.

   Examples
   --------
   >>> from sklearn.datasets import make_classification
   >>> X, y = make_classification(random_state=42)
   >>> X.shape
   (100, 20)
   >>> y.shape
   (100,)
   >>> list(y[:5])
   [0, 0, 1, 1, 0]


   .. py:method:: _lazy_make_classification_cpu(**kwargs)


   .. py:method:: _lazy_make_classification_gpu(**kwargs)


   .. py:method:: _make_classification_cpu(**kwargs)


   .. py:method:: _make_classification_gpu(**kwargs)


   .. py:method:: __call__(**kwargs)


